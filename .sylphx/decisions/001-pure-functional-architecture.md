# 001. Pure Functional Architecture

**Status:** âœ… Accepted
**Date:** 2024-11-16

## Context

Need to choose programming paradigm for neural network library. Options: OOP (classes, mutable state), functional (immutable, pure functions), or hybrid.

PyTorch uses OOP with in-place operations for performance. Brain.js uses classes. TensorFlow.js uses hybrid.

## Decision

Use **pure functional architecture** with immutable tensors and explicit state management.

## Rationale

- **Predictability**: No hidden mutations, easier to reason about
- **Testability**: Pure functions are trivial to test
- **Debugging**: Can replay operations, time-travel debugging
- **Serialization**: Immutable state is trivial to serialize
- **Concurrency**: No race conditions (future: Web Workers)
- **PyTorch familiarity**: Explicit state updates similar to PyTorch functional API

## Consequences

**Positive**:
- Zero mutation bugs
- Simple mental model
- Easy model serialization
- Enables advanced features (checkpointing, time-travel)

**Negative**:
- Performance cost of copying (mitigated by algorithmic optimization)
- Slightly more verbose (explicit state threading)
- Not idiomatic JavaScript (most JS libs use mutation)

**Mitigation**:
- Offset performance with tiling, loop unrolling, SIMD-style optimizations
- Achieved +22% vs naive implementation
- WASM/WebGPU provide escape hatch for critical paths

## References

<!-- VERIFY: packages/tensor/src/ops.ts -->
Implementation: `packages/tensor/src/ops.ts` (all operations return new tensors)
<!-- VERIFY: packages/nn/src/linear.ts -->
Example: `packages/nn/src/linear.ts` (layer functions take and return state)
<!-- VERIFY: packages/optim/src/adam.ts -->
Example: `packages/optim/src/adam.ts` (optimizer returns new model state)
